{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FedAdapt","text":"<p>FedAdapt extends FedScale with a live Dashboard, Self-Adaptive Personalization, and Heterogeneity-Aware Co-Optimization.</p> <p>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   REST / gRPC   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Dashboard Backend    \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  FedScale Aggregator &amp;  \u2502 \u2502  (FastAPI / Uvicorn) \u2502                \u2502      Executors          \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 HTTP / SSE \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Dashboard Frontend   \u2502 \u2502    (React + Vite)    \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</p>"},{"location":"#research-paper","title":"\ud83d\udcc4 Research Paper","text":"<p>Dive into the full design, theory, and experiments in our FedAdapt Research Paper (PDF).</p>"},{"location":"#overview-motivation","title":"\ud83d\ude80 Overview &amp; Motivation","text":"<p>Federated Learning (FL) allows training across many clients without centralizing their data, but real-world deployments face three key challenges:</p> <ol> <li> <p>Statistical heterogeneity    Clients collect data under wildly different distributions, slowing convergence and biasing the global model.</p> </li> <li> <p>System heterogeneity    Devices vary in compute power, network bandwidth, and availability, creating stragglers and wasted work.</p> </li> <li> <p>Observability gaps    Practitioners lack real-time dashboards to debug and monitor FL rounds, making tuning and deployment painful.</p> </li> </ol> <p>FedAdapt addresses all three with:</p> <ul> <li>Live Dashboard for end-to-end monitoring  </li> <li>Self-Adaptive Personalization that dynamically blends local/global models per client  </li> <li>Heterogeneity-Aware Co-Optimization that tunes each client's local-step count &amp; compression  </li> </ul>"},{"location":"#site-navigation","title":"\ud83e\udded Site Navigation","text":"<ol> <li> <p>Dashboard    See how to launch experiments, stream real-time metrics, and visualize global &amp; per-client charts.    \ud83d\udc49 dashboard.md</p> </li> <li> <p>Self-Adaptive Personalization    Learn how each client adaptively mixes its local and global weights for better per-user accuracy.    \ud83d\udc49 self_adaptive.md</p> </li> <li> <p>Heterogeneity-Aware Co-Optimization    Discover how we solve a tiny per-client grid-search each round to minimize compute + communication time.    \ud83d\udc49 cooptimization.md</p> </li> </ol>"},{"location":"#quick-start","title":"\u26a1 Quick Start","text":"<pre><code>git clone https://github.com/YourUser/FedAdapt.git\ncd FedAdapt\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n\n</code></pre> <p>```</p>"},{"location":"cooptimization/","title":"Co-Optimization","text":""},{"location":"cooptimization/#heterogeneity-aware-co-optimization","title":"Heterogeneity-Aware Co-Optimization","text":"<p>Dynamically tailor each client\u2019s work (local steps &amp; compression) to minimize per-round runtime.</p>"},{"location":"cooptimization/#motivation","title":"\ud83c\udfaf Motivation","text":"<p>Real-world devices vary wildly in compute speed, network bandwidth, and availability. A fixed \u201cone-size-fits-all\u201d choice of local steps or gradient compression can: - Slow down overall wall-clock convergence (stragglers) - Waste bandwidth on fast clients - Under-utilize powerful devices  </p> <p>Heterogeneity-Aware Co-Optimization automatically picks, per client per round, the best: - \ud835\udc58 = number of local SGD steps - \ud835\udc50 = compression ratio on the model update  </p> <p>to minimize [ T_i(k,c) = k \\cdot t_{\\text{comp},i} \\;+\\; c \\cdot B \\cdot t_{\\text{comm},i} ] where each client\u2019s compute &amp; comm timings ((t_{\\text{comp},i},t_{\\text{comm},i})) are profiled in-situ, and (B) is the model-update size.</p>"},{"location":"cooptimization/#how-it-works","title":"\u2699\ufe0f How It Works","text":"<p>Inside the Aggregator\u2019s <code>round_completion_handler()</code>:</p> <pre><code># profile: per\u2010client compute &amp; comm times\nprofiles = {\n    client: {\n      \"t_step\": comp_i,\n      \"t_comm\": comm_i / model_bits\n    }\n    for client, (comp_i, comm_i) in profiled_times.items()\n}\n\n# grid search over k \u2208 {1, default_steps}, c \u2208 {1.0, 0.5, 0.25}\nnew_conf = {}\nfor client, prof in profiles.items():\n    best = None\n    for k in [1, args.local_steps]:\n      for c in [1.0, 0.5, 0.25]:\n        T = k * prof[\"t_step\"] + c * model_bits * prof[\"t_comm\"]\n        if best is None or T &lt; best[0]:\n            best = (T, k, c)\n    new_conf[client] = Namespace(\n      local_steps=best[1],\n      compression=best[2],\n      batch_size=args.batch_size,\n      # \u2026other fields\u2026\n    )\n\nself.client_conf = new_conf\n&lt;!-- ```` --&gt;\n\nEach client then sees its tuned `(k, c)` on the next `CLIENT_TRAIN` event.\n\n---\n\n## \ud83d\udee0 Configuration\n\nExpose three fields in your CLI/REST and dashboard:\n\n| Flag / Form Field | Description | Default |\n| ----------------- | ----------- | :-----: |\n| `--optimize_for`  | Strategy:   |         |\n\n* **Fastest Training**\n* **Balanced**\n* **Best Accuracy**            | `Balanced` |\n  \\| `--compression_limit`| Maximum allowed compression ratio `[0.1\u20131.0]`  | `1.0`      |\n  \\| `--auto_tune`        | Enable/disable automatic per-client tuning     | `True`     |\n\n### Dashboard UI Snippet\n\n&lt;details&gt;\n&lt;summary&gt;&lt;strong&gt;Heterogeneity-Aware Optimization (settings)&lt;/strong&gt;&lt;/summary&gt;\n\n```jsx\n&lt;fieldset&gt;\n  &lt;legend&gt;Heterogeneity-Aware Optimization&lt;/legend&gt;\n\n  &lt;label&gt;\n    Optimize For:\n    &lt;select\n      name=\"optimize_for\"\n      value={form.optimize_for}\n      onChange={handleChange}\n    &gt;\n      &lt;option&gt;Fastest Training&lt;/option&gt;\n      &lt;option&gt;Balanced&lt;/option&gt;\n      &lt;option&gt;Best Accuracy&lt;/option&gt;\n    &lt;/select&gt;\n  &lt;/label&gt;\n\n  &lt;label&gt;\n    Compression Limit (c\u2098\u2090\u2093):\n    &lt;input\n      name=\"compression_limit\"\n      type=\"number\" step=\"0.1\" min=\"0.1\" max=\"1.0\"\n      value={form.compression_limit}\n      onChange={handleChange}\n    /&gt;\n  &lt;/label&gt;\n\n  &lt;label&gt;\n    Auto Tune:\n    &lt;select\n      name=\"auto_tune\"\n      value={form.auto_tune.toString()}\n      onChange={e =&gt; setForm(f =&gt; ({ \u2026f, auto_tune: e.target.value === 'true' }))}\n    &gt;\n      &lt;option value=\"true\"&gt;Enabled&lt;/option&gt;\n      &lt;option value=\"false\"&gt;Disabled&lt;/option&gt;\n    &lt;/select&gt;\n  &lt;/label&gt;\n&lt;/fieldset&gt;\n</code></pre>"},{"location":"cooptimization/#visualizing-co-optimization","title":"\ud83d\udcca Visualizing Co-Optimization","text":"<p>On the dashboard you can plot per-client choices each round:</p> <ul> <li>Local Steps (k) vs Round</li> <li>Compression Ratio (c) vs Round</li> <li>Bandwidth Saved (baseline \u2212 actual)</li> </ul> <p></p> <p>Tip:</p> <ul> <li>Lower <code>compression_limit</code> forces more aggressive sparsification.</li> <li>Disable <code>auto_tune</code> to use a single global <code>(k,c)</code> fallback.</li> </ul>"},{"location":"cooptimization/#defaults-tuning-tips","title":"\ud83d\udd27 Defaults &amp; Tuning Tips","text":"<ul> <li>Balanced: trades off compute vs. comm.</li> <li>Fastest Training: biases toward more local steps on fast clients.</li> <li>Best Accuracy: biases toward lower compression.</li> <li>If you care more about accuracy than speed, pick Best Accuracy and set <code>compression_limit</code> near 1.0.</li> </ul>"},{"location":"cooptimization/#architecture","title":"\ud83c\udfd7 Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      gRPC      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FastAPI / Uvicorn   \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  FedScale Aggregator\u2502\n\u2502 (dashboard-backend)  \u2502                \u2502    &amp; Executor      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                                    \u25b2\n         \u2502 HTTP / SSE                        \u2502 Grid\u2010search (k,c)\n         \u25bc                                    \u2502 per\u2010client\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502  React + Vite        \u2502                      \u25bc\n\u2502 (dashboard-frontend) \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502   Co-Optimizer     \u2502\n                                        \u2502 (in Aggregator)    \u2502\n                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Read more in the research paper or see the code in <code>fedscale/cloud/aggregation/aggregator.py \u2192 Aggregator.round_completion_handler()</code></p> <p>````</p>"},{"location":"dashboard/","title":"Dashboard","text":""},{"location":"dashboard/#live-dashboard","title":"Live Dashboard","text":"<p>FedAdapt\u2019s real-time web UI to launch and monitor federated experiments.</p>"},{"location":"dashboard/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"dashboard/#1-backend","title":"1. Backend","text":"<pre><code>cd dashboard-backend\npip install -r requirements.txt\nuvicorn app.main:app --reload --port 8000\n&lt;!-- ```` --&gt;\n\n### 2. Frontend\n\n```bash\ncd dashboard-frontend\nnpm install\nnpm run dev\n</code></pre> <p>Your dashboard will be available at:</p> <ul> <li>Backend API: <code>http://localhost:8000</code></li> <li>Frontend UI: <code>http://localhost:3000</code></li> </ul>"},{"location":"dashboard/#architecture-overview","title":"\ud83c\udfd7 Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      gRPC      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FastAPI / Uvicorn   \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  FedScale Aggregator\u2502\n\u2502 (dashboard-backend)  \u2502                \u2502    &amp; Executor      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502 HTTP / SSE\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  React + Vite        \u2502\n\u2502 (dashboard-frontend) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li> <p>dashboard-backend</p> </li> <li> <p>FastAPI (REST + Server-Sent Events)</p> </li> <li>Spawns FedScale Aggregator &amp; Executor processes</li> <li> <p>Proxies gRPC to HTTP/SSE endpoints</p> </li> <li> <p>dashboard-frontend</p> </li> <li> <p>React + Vite</p> </li> <li>Axios for REST calls</li> <li>EventSource for live updates (SSE)</li> <li>React Router for navigation</li> </ul>"},{"location":"dashboard/#backend-endpoints","title":"\ud83d\udd0c Backend Endpoints","text":"Method Path Description POST <code>/experiments</code> Start a new experiment GET <code>/experiments</code> List active experiments POST <code>/experiments/{id}/stop</code> Stop a running experiment GET <code>/experiments/{id}/status</code> Current round, running flag, sampled clients GET <code>/experiments/{id}/round/{r}/metrics</code> Metrics for round <code>r</code> GET <code>/experiments/{id}/stream</code> SSE stream of status &amp; metrics GET <code>/experiments/{id}/data</code> Raw JSON payloads from <code>data/{id}/</code> GET <code>/experiments/{static_id}/static</code> Static results for completed experiments GET <code>/health</code> Health check \u2192 <code>{\"status\":\"ok\"}</code>"},{"location":"dashboard/#experimentstartrequest-schema","title":"ExperimentStartRequest schema","text":"<pre><code>{\n  \"name\": \"string\",\n  \"num_executors\": 1,\n  \"num_clients\": 4,\n  \"gradient_policy\": \"FedAvg\",\n  \"experiment_mode\": \"SIMULATION\",\n  \"backend\": \"gloo\",\n  \"engine\": \"pytorch\",\n  \"model_zoo\": \"vision\",\n  \"model\": \"resnet18\",\n  \"data_set\": \"cifar10\",\n  \"data_dir\": \"/data\",\n  \"input_shape\": \"3,32,32\",\n  \"output_dim\": 10,\n  \"num_classes\": 10,\n  \"rounds\": 5,\n  \"local_steps\": 1,\n  \"batch_size\": 8,\n  \"eval_interval\": 1,\n  \"optimize_for\": \"Balanced\",\n  \"compression_limit\": 0.5,\n  \"auto_tune\": true,\n  \"alpha_threshold\": 0.02,\n  \"alpha_step\": 0.10\n}\n</code></pre>"},{"location":"dashboard/#ui-walkthrough","title":"\ud83d\udda5\ufe0f UI Walkthrough","text":""},{"location":"dashboard/#1-start-new-experiment","title":"1. Start New Experiment","text":"<ul> <li>Main Settings: experiment name, number of clients/executors, FL mode</li> <li>Model &amp; Data: select model zoo, dataset, input shape, classes</li> <li>Training Hyperparameters: rounds, batch size, learning rate, etc.</li> <li>Heterogeneity Co-Opt: optimization target, compression limit</li> <li>Self-Adaptive Personalization: \u03b1 threshold &amp; step</li> </ul> <p>Click Start Experiment \u2192 you\u2019ll be redirected to the live metrics view.</p>"},{"location":"dashboard/#2-completed-experiments","title":"2. Completed Experiments","text":"<ul> <li>Expand each experiment group</li> <li>Click a variant to view its static results page</li> </ul>"},{"location":"dashboard/#3-live-metrics","title":"3. Live Metrics","text":"<ul> <li>Global Charts: test loss &amp; accuracy vs. round</li> <li>Client Panels: per-client loss, duration, \u03b1 trajectories</li> <li>Bandwidth Savings (when compression is enabled)</li> <li>Straggler Profiles: visualizing slow clients</li> </ul> <p>All live updates stream over SSE from <code>/experiments/{id}/stream</code>.</p>"},{"location":"dashboard/#production-notes","title":"\ud83d\udd27 Production Notes","text":"<ul> <li>CORS is currently unrestricted (<code>allow_origins: [\"*\"]</code>)\u2014lock it down for production.</li> <li>Ensure the FedScale aggregator gRPC server is listening on <code>127.0.0.1:50051</code>.</li> </ul> <p>Next up: Self-Adaptive Personalization</p> <pre><code></code></pre>"},{"location":"self_adaptive/","title":"Personalization","text":""},{"location":"self_adaptive/#self-adaptive-personalization","title":"Self-Adaptive Personalization","text":"<p>Dynamically blend each client\u2019s local and global model per round to mitigate non-IID drift.</p>"},{"location":"self_adaptive/#motivation","title":"\ud83c\udfaf Motivation","text":"<p>Federated Learning on non-IID data can bias the global model toward dominant shards. Self-Adaptive Personalization lets each client maintain both: - a local model updated on its own data - the global model received from the server  </p> <p>Each round, the client automatically adjusts a mixing weight \u03b1\u2208[0,1] to favor whichever model currently performs better on held-out data.</p>"},{"location":"self_adaptive/#how-it-works","title":"\u2699\ufe0f How It Works","text":"<ol> <li>Evaluate both models on the client\u2019s validation split:    ```python    local_acc  = self.evaluate_model(self.local_weights)    global_acc = self.evaluate_model(self.global_weights)</li> </ol> <ol> <li>Adjust the mixing weight \u03b1 by threshold \u03c4 and step \u0394:</li> </ol> <p><code>python    if local_acc - global_acc &gt; \u03c4:        self.alpha = min(self.alpha + \u0394, 1.0)    elif global_acc - local_acc &gt; \u03c4:        self.alpha = max(self.alpha - \u0394, 0.0)</code> 3. Mix the weights before training:</p> <p><code>python    mixed = [      self.alpha * lw + (1 - self.alpha) * gw      for lw, gw in zip(self.local_weights, self.global_weights)    ]    self.model_adapter.set_weights(mixed, is_aggregator=False)</code> 4. Train with standard local SGD on <code>mixed</code>, then store updated weights in <code>self.local_weights</code>.</p>"},{"location":"self_adaptive/#configuration","title":"\ud83d\udee0 Configuration","text":"<p>Expose two hyperparameters in both CLI/REST and the dashboard UI:</p> Flag / Form Field Description Default <code>--alpha_threshold</code> \u03c4: min accuracy gap to adjust \u03b1 0.02 <code>--alpha_step</code> \u0394: step size for \u03b1 adjustments 0.10"},{"location":"self_adaptive/#dashboard-ui-snippet","title":"Dashboard UI Snippet","text":"Self-Adaptive Personalization (settings) <pre><code>&lt;fieldset&gt;\n  &lt;legend&gt;Self-Adaptive Personalization&lt;/legend&gt;\n  &lt;label&gt;\n    \u03b1-threshold (\u03c4):\n    &lt;input\n      name=\"alpha_threshold\"\n      type=\"number\" step=\"0.005\" min=\"0\" max=\"1\"\n      value={form.alpha_threshold}\n      onChange={handleChange}\n    /&gt;\n  &lt;/label&gt;\n  &lt;label&gt;\n    \u03b1-step (\u0394):\n    &lt;input\n      name=\"alpha_step\"\n      type=\"number\" step=\"0.01\" min=\"0\" max=\"1\"\n      value={form.alpha_step}\n      onChange={handleChange}\n    /&gt;\n  &lt;/label&gt;\n&lt;/fieldset&gt;\n</code></pre>"},{"location":"self_adaptive/#visualizing-personalization","title":"\ud83d\udcca Visualizing Personalization","text":"<p>Your dashboard can chart each client\u2019s \u03b1 over rounds:</p> <p></p> <p>Tip: Higher \u03c4/\u0394 makes \u03b1 more conservative (slower to adapt). To push for stronger personalization, lower \u03c4 or increase \u0394.</p>"},{"location":"self_adaptive/#defaults-tuning-tips","title":"\ud83d\udd27 Defaults &amp; Tuning Tips","text":"<ul> <li> <p>Defaults:</p> </li> <li> <p>\u03c4 = 0.02, \u0394 = 0.10 (empirically stable for CIFAR-10, Dirichlet \u03b1=0.5)</p> </li> <li> <p>More personalization:</p> </li> <li> <p>Lower \u03c4 \u2192 more frequent \u03b1 updates</p> </li> <li>Increase \u0394 \u2192 larger jumps in \u03b1 per round</li> <li>Less personalization: do the opposite (higher \u03c4, smaller \u0394)</li> </ul>"},{"location":"self_adaptive/#architecture","title":"\ud83c\udfd7 Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      gRPC      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FastAPI / Uvicorn   \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  FedScale Aggregator\u2502\n\u2502 (dashboard-backend)  \u2502                \u2502    &amp; Executor      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                                    \u25b2\n         \u2502 HTTP / SSE                        \u2502 Evaluate + Mix\n         \u25bc                                    \u2502 Adjust \u03b1\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502 Train on mixed weights\n\u2502  React + Vite        \u2502                      \u2502\n\u2502 (dashboard-frontend) \u2502                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u25bc\n                                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                      \u2502   Local Client     \u2502\n                                      \u2502(self-adaptive logic)\u2502\n                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ol> <li>Dashboard/API: user sets \u03c4, \u0394</li> <li>Executor: each round \u2192 evaluate local vs global \u2192 adjust \u03b1 \u2192 mix \u2192 train</li> <li>Aggregator: standard FL orchestration + streams metrics</li> </ol> <p>Read more about the math and implementation in the research paper or see the code in <code>fedscale/cloud/execution/executor.py \u2192 Executor.Train()</code></p> <pre><code></code></pre>"}]}